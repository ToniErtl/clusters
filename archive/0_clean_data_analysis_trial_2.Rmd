---
title: "Clustering article - title tbd"
author: "Antal Ertl"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)


library(tidyverse)
library(tidymodels)
library(ggplot2)
library(ggthemes)
library(rgl) # 3 dimensional plots
library(cluster)
library(factoextra)

corrplot2 <- function(data,
                      method = "pearson",
                      sig.level = 0.05,
                      order = "original",
                      diag = FALSE,
                      type = "upper",
                      tl.srt = 90,
                      number.font = 1,
                      number.cex = 1,
                      mar = c(0, 0, 0, 0)) {
  library(corrplot)
  data_incomplete <- data
  data <- data[complete.cases(data), ]
  mat <- cor(data, method = method)
  cor.mtest <- function(mat, method) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat <- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], method = method)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  p.mat <- cor.mtest(data, method = method)
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  corrplot(mat,
    method = "color", col = col(200), number.font = number.font,
    mar = mar, number.cex = number.cex,
    type = type, order = order,
    addCoef.col = "black", # add correlation coefficient
    tl.col = "black", tl.srt = tl.srt, # rotation of text labels
    # combine with significance level
    p.mat = p.mat, sig.level = sig.level, insig = "blank",
    # hide correlation coefficiens on the diagonal
    diag = diag
  )
}

```

```{r load data}
data <- read.csv(".//Data in brief//Horn-Kiss-Lenard2021.csv")
```


<!-- ### Exploratory Data Analysis -->

```{r correlation matrix, include=FALSE}


# just to look at it; too complex to publish anything

# cor_matrix_data <- data %>% 
#                           select(#academic,
#                                    FinalProfitRounded,
#                                    delta,
#                                    #delta_now,
#                                    beta,
#                                    #pb,
#                                    #beta_0,
#                                    dictator,
#                                    dictator_schoolmate,
#                                    risk,
#                                    publicgood,
#                                    trust,
#                                    trust_return,
#                                    comp,
#                                    SPiecerate,
#                                    STournament,
#                                    # SPiecerateChoosed,
#                                    # STournamentChoosed,
#                                    RankP,
#                                    RankT,
#                                    math,
#                                    read,
#                                    gpa_i)%>% 
#   tidyr::drop_na() %>% 
# 
# corrplot2(
#   data = cor_matrix_data,
#   method = "pearson",
#   sig.level = 0.05,
#   order = "original",
#   diag = FALSE,
#   type = "upper",
#   tl.srt = 75
# )
```


#PCA computation




```{r}
# get data ready

pca_data <- data %>%  mutate(STournamentChoosed =replace_na(STournamentChoosed,0)) %>% 
        mutate(STournamentChoosed_comp =STournamentChoosed* comp) %>% 
                     dplyr::select(studid,
                                   delta,
                                   #delta_now,
                                   beta,
                                   #pb,
                                   beta_0, # time inconsistency
                                   dictator, #altruism
                                   dictator_schoolmate, #altruism
                                   risk, # risk
                                   publicgood, # cooperativeness
                                   trust, # trust
                                   trust_return) %>%  #trust
                                   #SPiecerate,
                                   #STournament,
                                   #STournamentChoosed_comp,
                                   #RankP,
                                   #RankT) %>% 
                                   # SPiecerateChoosed,
                                   # STournamentChoosed,
                                   # comp %>% 
  #STANDARDIZATION
  # mutate_at(c('delta',
  #             #delta_now,
  #                                  'beta',
  #                                  #pb,
  #                                  'beta_0',
  #                                  'dictator',
  #                                  'dictator_schoolmate',
  #                                  'risk',
  #                                  'publicgood',
  #                                  'trust',
  #                                  'trust_return'
  #                                  # 'SPiecerate',
  #                                  # 'STournament',
  #                                  # 'RankP',
  #                                  # 'RankT'
  #                                  # SPiecerateChoosed,
  #                                  # STournamentChoosed
  #             ), ~(scale(.) %>% as.vector)) %>% 
  #mutate(comp=as.factor(comp)) %>% 
  drop_na()


pr.out <- pca_data %>% select(-studid) %>% prcomp(., scale = TRUE)

```


Scree-plot: based on this, around 4 is the optimal number of clusters for PCA

```{r, warning=FALSE,dpi=300, fig.width=10, fig.height=4}

scree_plot_data <- pca_data %>%  select(-studid) %>% psych::principal( nfactors = 5, rotate= "varimax")

pve <- 100 * pr.out$sdev^2 / sum(pr.out$sdev ^2)
par(mfrow = c(1, 2))
plot(pve , type = "o", ylab = "PVE", main = "Scree-plot for Principal Component Analysis", frame = FALSE, xlab = "Principal Component", col = "blue")
```


Parallel Analysis: specify how many components to retain using simulation

Here, we get the critical values for each component. If the eigenvalues from the PCA are greater than the value at 0.95 confint, we can retain given component.

We have two rules: 
1) Kaiser's rule: Eigenvalue has to be >1 (satisfied up to 4 factors, with the 4th being barely above)
2) Eigenvalues being greater than the estimates gathered from Parallel Analysis (Horn, 1965)

```{r, warning=FALSE}


library(hornpa)
hornpa(k = 5, #test for number of factors
       size = nrow(pca_data), # size of dataset
       reps = 500, # number of simulations
       seed = 1234) #set seed 

scree_plot_data

rm(scree_plot_data,pve)

```


Use varimax rotation for the data (just as Chapman et al.(2022) did) For 3 factors

```{r}


pca_varimax<- pca_data %>%  select(-studid,beta_0) %>% psych::principal( nfactors = 3, rotate= "varimax")

pca_varimax$loadings
```

Graph of the contents of the 3 components:

```{r}
data.frame(head(pca_varimax$loadings, n=nrow(pca_varimax$loadings))) %>%
  mutate(variable = rownames(.)) %>% 
  gather(component,loading,-variable) %>% 
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component")+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()

```


```{r}
trial1 <- pca_data %>% select(trust_return,trust,publicgood) %>% psych::principal(nfactors = 1, rotate = "varimax")

trial2 <- pca_data %>% select(delta,beta,beta_0) %>% psych::principal(nfactors = 1, rotate = "varimax")

trial3 <- pca_data %>% select(dictator,dictator_schoolmate) %>% psych::principal(nfactors = 1, rotate = "varimax")

t1_scores <-data.frame(trial1$scores)
t2_scores <-data.frame(trial2$scores)
t3_scores <-data.frame(trial3$scores)


plotdata <- data.frame(p1 =t1_scores,
                       p2= t2_scores,
                       p3 =t3_scores)

plot3d( 
  x=plotdata$PC1, y=plotdata$PC1.1, z=plotdata$PC1.2, 
  #col = data$color, 
  #type = 's', 
  radius = .2,
  xlab="RC1", ylab="RC2", zlab="RC3")

cor(t1_scores,t3_scores)
```



PCA for 4 factors:

```{r}
pca_varimax<- pca_data %>%  select(-studid,beta_0) %>% psych::principal( nfactors = 4, rotate= "varimax")


pca_varimax$loadings

data.frame(head(pca_varimax$loadings, n=nrow(pca_varimax$loadings))) %>%
  mutate(variable = rownames(.)) %>% 
  gather(component,loading,-variable) %>% 
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component",
      subtitle ="With 4 factors")+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()


```





```{r}
plot3d( 
  x=pca_data$dictator_schoolmate, y=pca_data$delta, z=pca_data$publicgood, 
  #col = data$color, 
  #type = 's', 
  radius = .2,
  xlab="RC1", ylab="RC2", zlab="RC3")
```




```{r, include = FALSE}

#3d plot

pca_varimax_3d_plot <-data.frame(pca_varimax$scores)
  
plot3d( 
  x=pca_varimax_3d_plot$RC1, y=pca_varimax_3d_plot$RC2, z=pca_varimax_3d_plot$RC3, 
  #col = data$color, 
  #type = 's', 
  radius = .2,
  xlab="RC1", ylab="RC2", zlab="RC3")
```


```{r}
plot3d( 
  x=pca_varimax_3d_plot$RC1, y=pca_varimax_3d_plot$RC4, z=pca_varimax_3d_plot$RC3, 
  #col = data$color, 
  #type = 's', 
  radius = .2,
  xlab="RC1", ylab="RC4", zlab="RC3")
```


<!-- 2d plot for the first two dimensions -->

```{r, include=FALSE}
data.frame(pca_varimax$scores) %>% 
  ggplot(aes(RC1, RC2)) +
  geom_point(color = "midnightblue", alpha = 0.7, size = 2) +
  #geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") +
  labs(color = NULL)


```







# PCA including competition


Here, I do the same analysis, but I include  the interaction term 'STournamentChoosed_comp = STournamentChoosed* comp'


```{r}

# xData :

pca_data2 <- data %>%  mutate(STournamentChoosed =replace_na(STournamentChoosed,0)) %>% 
        mutate(STournamentChoosed_comp =STournamentChoosed* comp) %>% 
                     dplyr::select(studid,
                                   delta,
                                   #delta_now,
                                   beta,
                                   #pb,
                                   beta_0, # time inconsistency
                                   dictator, #altruism
                                   dictator_schoolmate, #altruism
                                   risk, # risk
                                   publicgood, # cooperativeness
                                   trust, # trust
                                   trust_return,  #trust
                                   #SPiecerate,
                                   #STournament,
                                   STournamentChoosed_comp) %>%
                                   #RankP,
                                   #RankT) %>% 
                                   # SPiecerateChoosed,
                                   # STournamentChoosed,
                                   # comp %>% 
  #STANDARDIZATION
  # mutate_at(c('delta',
  #             #delta_now,
  #                                  'beta',
  #                                  #pb,
  #                                  'beta_0',
  #                                  'dictator',
  #                                  'dictator_schoolmate',
  #                                  'risk',
  #                                  'publicgood',
  #                                  'trust',
  #                                  'trust_return'
  #                                  # 'SPiecerate',
  #                                  # 'STournament',
  #                                  # 'RankP',
  #                                  # 'RankT'
  #                                  # SPiecerateChoosed,
  #                                  # STournamentChoosed
  #             ), ~(scale(.) %>% as.vector)) %>% 
  #mutate(comp=as.factor(comp)) %>% 
  drop_na()

pr.out2 <- pca_data2 %>% select(-studid) %>% prcomp(., scale = TRUE)


```


Scree-plot and Parallel analysis says pretty much the same.

```{r, warning=FALSE,dpi=300, fig.width=10, fig.height=4}
scree_plot_data2 <- pca_data2 %>%  select(-studid) %>% psych::principal( nfactors = 5, rotate= "varimax")

pve <- 100 * pr.out2$sdev^2 / sum(pr.out2$sdev ^2)
par(mfrow = c(1, 2))

plot(pve , type = "o", ylab = "PVE", main = "Scree-plot for Principal Component Analysis",
xlab = "Principal Component", col = "blue")
```


<!-- Parallel Analysis: specify how many components to retain using simulation -->

<!-- here, we get the critical values for each component. If the eigenvalues from the PCA are greater than the value at 0.95 confint, we can retain given component. -->

<!-- We have two rules:  -->
<!-- 1) Kaiser's rule: Eigenvalue has to be >1 (satisfied up to 4 factors, with the 4th being barely above) -->
<!-- 2) Eigenvalues being greater than the estimates gathered from Parallel Analysis (Horn, 1965) -->

```{r, warning=FALSE}


library(hornpa)
hornpa(k = 5, #test for number of factors
       size = nrow(pca_data2), # size of dataset
       reps = 500, # number of simulations
       seed = 1234) #set seed 

scree_plot_data2

rm(scree_plot_data2,pve)

```


Use varimax rotation for the data (just as Chapman et al.(2022) did) For 3 components

```{r}


pca_varimax2<- pca_data2 %>%  select(-studid) %>% psych::principal( nfactors = 3, rotate= "varimax")

pca_varimax2$loadings
```

Graph of the contents of the 3 components:

```{r}

data.frame(head(pca_varimax2$loadings, n=nrow(pca_varimax2$loadings))) %>%
  mutate(variable = rownames(.)) %>% 
  gather(component,loading,-variable) %>% 
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component: with competition",
       subtitle = "With 3 factors")+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()


```

With 4 components:

```{r}
pca_varimax2_4<- pca_data2 %>%  select(-studid) %>% psych::principal( nfactors = 4, rotate= "varimax")

pca_varimax2_4$loadings

data.frame(head(pca_varimax2_4$loadings, n=nrow(pca_varimax2_4$loadings))) %>%
  mutate(variable = rownames(.)) %>% 
  gather(component,loading,-variable) %>% 
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component: with competition",
       subtitle = "With 4 factors",
       caption ="STournamentChoosed_comp =STournamentChoosed x comp" )+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()

```

---------------------------------



# FAMD - Factor Analysis for Mixed Data

FAMD is essentially a PCA method we can use for both continuous and categorical data (a mix between PCA and MCA)

From FactoMineR package:

"FAMD is a principal component method dedicated to explore data with both continuous and cate-
gorical variables. It can be seen roughly as a mixed between PCA and MCA. More precisely, the
continuous variables are scaled to unit variance and the categorical variables are transformed into a
disjunctive data table (crisp coding) and then scaled using the specific scaling of MCA. This ensures
to balance the influence of both continous and categorical variables in the analysis. It means that
both variables are on a equal foot to determine the dimensions of variability. This method allows
one to study the similarities between individuals taking into account mixed variables and to study
the relationships between all the variables. It also provides graphical outputs such as the repre-
sentation of the individuals, the correlation circle for the continuous variables and representations
of the categories of the categorical variables, and also specific graphs to visulaize the associations
between both type of variables."

```{r, warning = FALSE}
FAMD_data <- data %>% dplyr::select(delta,
                                   #delta_now,
                                   beta,
                                   #pb,
                                   #beta_0,
                                   dictator,
                                   dictator_schoolmate,
                                   risk,
                                   publicgood,
                                   trust,
                                   trust_return,
                                   SPiecerate,
                                   STournament,
                                  # RankP,
                                  # RankT,
                                   # SPiecerateChoosed,
                                   # STournamentChoosed,
                                   comp) %>% 
  #STANDARDIZATION
  mutate_at(c('delta',
              #delta_now,
                                   'beta',
                                   #pb,
                                   #beta_0,
                                   'dictator',
                                   'dictator_schoolmate',
                                   'risk',
                                   'publicgood',
                                   'trust',
                                   'trust_return',
                                   'SPiecerate',
                                   'STournament'
                                  # 'RankP',
                                  # 'RankT'
                                   # SPiecerateChoosed,
                                   # STournamentChoosed
              ), ~(scale(.) %>% as.vector)) %>% 
  mutate(comp=as.factor(comp)) %>% 
  drop_na()


library(FactoMineR)

FAMD_test <- FAMD (FAMD_data, 
                   ncp = 4, # number of dimensions kept; default is 5 
                   graph = TRUE,
                   sup.var = NULL,
                  ind.sup = NULL, 
                  axes = c(1,2), # a length 2 vector specifying the components to plot
                  row.w = NULL,
                  tab.disj = NULL) # object obtained from the imputeFAMD function of the missMDA package that allows to handle missing values
#FAMD_test
```



```{r}
summary(FAMD_test)
```

---------------------------------------------




# Clustering test

Here I am combining clustering methods (k-means) with PCA to visualize clusters. I did it for various numbers of cluster-centers.

Overall, we can't really show in 2 dimensions the effectiveness of clustering.

```{r}


cluster_test_data<- data %>%  mutate(STournamentChoosed_comp =STournamentChoosed* comp) %>% 
                              select(delta_now,
                                   beta,
                                   #pb,
                                   beta_0,
                                   dictator,
                                   dictator_schoolmate,
                                   risk,
                                   publicgood,
                                   trust,
                                   trust_return,
                                   SPiecerate,
                                   STournament,
                                   RankP,
                                   RankT,
                                   STournamentChoosed_comp,
                                   # SPiecerateChoosed,
                                   # STournamentChoosed,
                                   comp,
                                   age,
                                   FinalProfitRounded,
                                   math,
                                   read,
                                   gpa_i) %>% 
  drop_na() %>% 
  mutate(comp=as.numeric(comp))

# elbow method:

set.seed(123)

# function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(cluster_test_data, k, nstart = 100 )$tot.withinss
}

# Compute and plot wss for k = 1 to k = 15
k.values <- 1:50

# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")


```

```{r}
#setup database
k2 <- kmeans(cluster_test_data, centers = 2, nstart = 1000)
k3 <- kmeans(cluster_test_data, centers = 3, nstart = 1000)
k4 <- kmeans(cluster_test_data, centers = 4, nstart = 1000)
k5 <- kmeans(cluster_test_data, centers = 5, nstart = 1000)


p1 <- fviz_cluster(k2, geom = "point", data = cluster_test_data) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = cluster_test_data) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = cluster_test_data) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = cluster_test_data) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
# 
# k5 <- kmeans(cluster_test_data, centers = 3, nstart = 100)
# 
# fviz_cluster(k5, geom = "point",  data = cluster_test_data) + ggtitle("k = 5")
```






### use scores from PCA to identify clusters


```{r}

pca_varimax<- pca_data %>%  select(-studid,beta_0) %>% psych::principal(nfactors = 4, rotate= "quartimax")



data.frame(head(pca_varimax$loadings, n=nrow(pca_varimax$loadings))) %>%
  mutate(variable = rownames(.)) %>%
  gather(component,loading,-variable) %>%
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component",
      subtitle ="With 4 factors")+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()

pca_data$pca_comp1 <- pca_varimax$scores[,1]
pca_data$pca_comp2 <- pca_varimax$scores[,2]
pca_data$pca_comp3 <- pca_varimax$scores[,3]
pca_data$pca_comp4 <- pca_varimax$scores[,4]




# add variables from the original data

additional_variables <- data %>%
select(studid,
         classid,
         schoolid,
         academic,
         comp,
         FinalProfitRounded,
         math,
         read,
         female,
         male,
         age,
         gpa_i,
         grade_math,
         grade_hun,
         grade_lit)



data_analysis <- left_join(pca_data,additional_variables, by ="studid")



data_analysis_clean <- data_analysis %>%
  # select(-delta, # I am removing all data that pca components include
  #        -beta,
  #        -beta_0,
  #        -dictator,
  #        -dictator_schoolmate,
  #        -risk,
  #        -publicgood,
  #        -trust,
  #        -trust_return)%>%
  drop_na() %>% 
  mutate(good_stud = case_when(gpa_i>=4.75~1,
                               TRUE~0))




summary(glm(good_stud~pca_comp1+pca_comp2+pca_comp3+pca_comp4, data=data_analysis_clean))


```


```{r}

plot3d(
  x=pca_data$pca_comp2, y=pca_data$pca_comp3, z=pca_data$pca_comp4,
  #col = data$color,
  #type = 's',
  radius = .1,
  xlab="PC2", ylab="PC3", zlab="PC4")

```


```{r}

summary(lm(FinalProfitRounded~., data= data_analysis_clean))

```









# Dendogram





```{r}

hc.complete <- hclust(dist(data_analysis_clean), method = "complete")
par(mfrow = c(1, 3))
plot(hc.complete , main = "Complete Linkage",
xlab = "", sub = "", cex = .9)


clustdata2<- data_analysis_clean %>% select(pca_comp1,pca_comp2,pca_comp3,pca_comp4)
hc.complete <- hclust(dist(clustdata2), method = "complete")
hc.average <- hclust(dist(clustdata2), method = "average")
par(mfrow = c(1, 2))
plot(hc.complete , main = "Complete Linkage",
xlab = "", sub = "", cex = .9)
plot(hc.average , main = "Average Linkage",
xlab = "", sub = "", cex = .9)

```


6.5 cute-off value (ad hoc, I know); I will try to test it:

```{r}
hc.complete <- hclust(dist(data_analysis_clean), method = "complete")




plot(hc.complete, main="Clusters created at height = 6.5", sub ="5 clusters with one outlier")
rect.hclust(hc.complete , h = 6.5, border = 2:7)
abline(h = 6.5, col = 'red')
```
```{r}

dendagram <- as.dendrogram(hc.complete)

LAB = rep("", nobs(dendagram))
dendagram = dendextend::set(dendagram, "labels", LAB) 

plot(dendextend::color_branches(dendagram, k = 6), main="Clusters created at height = 6.5", sub ="5 clusters with one outlier", leaflab = "none", horiz = F)
#rect.hclust(hc.complete , h = 6.5, border = 2:7)
abline(h = 6.5, col = 'red')


```


```{r}
hc.complete <- hclust(dist(clustdata2), method = "complete")

cut_complete <- cutree(hc.complete, h=6.5)

clustdata2$clusters <- cut_complete

pairs(clustdata2[,1:4], pch = 19,cex =0.7,
      col = as.factor(clustdata2$clusters),
      lower.panel=NULL)



```

In the end, we have to cut the 





elbow plottal k-meansre ránézek:

```{r}

set.seed(42)

# function to compute total within-cluster sum of square 
wss <- function(k) {
  kmeans(clustdata2, k, nstart = 100 )$tot.withinss
}

# Compute and plot wss for k = 1 to k = 50
k.values <- 1:50

# extract wss for 2-50 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")


```










<!-- ---------------------------------------------------------------------------------------------- -->

<!-- ### PCA - analysis with tidymodels -->

<!-- PCA cannot use binary variables - I omitted the "comp" variable, but included the comp*STournamentChoose interaction -->


<!-- ```{r} -->

<!-- pca_data <- data %>%  mutate(STournamentChoosed =replace_na(STournamentChoosed,0)) %>%  -->
<!--         mutate(STournamentChoosed_comp =STournamentChoosed* comp) %>%  -->
<!--                      dplyr::select(studid, -->
<!--                                    delta, -->
<!--                                    #delta_now, -->
<!--                                    beta, -->
<!--                                    #pb, -->
<!--                                    #beta_0, -->
<!--                                    dictator, #altruism -->
<!--                                    dictator_schoolmate, #altruism -->
<!--                                    risk, -->
<!--                                    publicgood, # cooperativeness -->
<!--                                    trust, # trust -->
<!--                                    trust_return, #trust -->
<!--                                    SPiecerate, -->
<!--                                    STournament, -->
<!--                                    STournamentChoosed_comp, -->
<!--                                    RankP, -->
<!--                                    RankT) %>%  -->
<!--                                    # SPiecerateChoosed, -->
<!--                                    # STournamentChoosed, -->
<!--                                    # comp %>%  -->
<!--   #STANDARDIZATION -->
<!--   mutate_at(c('delta', -->
<!--               #delta_now, -->
<!--                                    'beta', -->
<!--                                    #pb, -->
<!--                                    #beta_0, -->
<!--                                    'dictator', -->
<!--                                    'dictator_schoolmate', -->
<!--                                    'risk', -->
<!--                                    'publicgood', -->
<!--                                    'trust', -->
<!--                                    'trust_return', -->
<!--                                    'SPiecerate', -->
<!--                                    'STournament', -->
<!--                                    'RankP', -->
<!--                                    'RankT' -->
<!--                                    # SPiecerateChoosed, -->
<!--                                    # STournamentChoosed -->
<!--               ), ~(scale(.) %>% as.vector)) %>%  -->
<!--   #mutate(comp=as.factor(comp)) %>%  -->
<!--   drop_na() -->



<!-- pca_rec <- recipe(~., data = pca_data) %>% -->
<!--   update_role(studid, new_role = "id") %>% -->
<!--   step_normalize(all_predictors()) %>% -->
<!--   step_pca(all_predictors(), num_comp = 5) -->

<!-- pca_prep <- prep(pca_rec) -->

<!-- bake(pca_prep, new_data = NULL) %>% -->
<!--   ggplot(aes(PC1, PC2, label = studid)) + -->
<!--   geom_point(color = "midnightblue", alpha = 0.7, size = 2) + -->
<!--   geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") + -->
<!--   labs(color = NULL) -->
<!-- ``` -->


<!-- ```{r} -->

<!-- data_3dplot <- bake(pca_prep, new_data = NULL) -->

<!-- plot3d(  -->
<!--   x=data_3dplot$PC1, y=data_3dplot$PC2, z=data_3dplot$PC3,  -->
<!--   #col = data$color,  -->
<!--   #type = 's',  -->
<!--   radius = .1, -->
<!--   xlab="PC1", ylab="PC2", zlab="PC3") -->
<!-- ``` -->


<!-- ```{r} -->
<!-- pca_comps <- tidy(pca_prep, 2) %>% -->
<!--   filter(component %in% paste0("PC", 1:4)) %>%  -->
<!--   group_by(component) %>% -->
<!--   top_n(8, abs(value)) %>% -->
<!--   ungroup() -->


<!-- pca_comps %>% -->
<!--  #mutate(value = abs(value)) %>% -->
<!--   ggplot(aes(value, terms)) + -->
<!--   geom_col(position = "dodge", fill="midnightblue") + -->
<!--   facet_wrap(~component) + -->
<!--   labs( -->
<!--     x = "Value of contribution", -->
<!--     y = NULL, fill = NULL, -->
<!--     title = "Importance of variables in each PC", -->
<!--     fill=NULL -->
<!--   )+ -->
<!--   theme_minimal() -->


<!-- # pca_comps %>% -->
<!-- #  # mutate(value = abs(value)) %>% -->
<!-- #   ggplot(aes(value, fct_reorder(terms, value))) + -->
<!-- #   geom_col(position = "dodge", fill="midnightblue") + -->
<!-- #   facet_wrap(~component, scales = "free_y") + -->
<!-- #   labs( -->
<!-- #     x = "Value of contribution", -->
<!-- #     y = NULL, fill = NULL, -->
<!-- #     title = "Importance of variables in each PC", -->
<!-- #     fill=NULL -->
<!-- #   )+ -->
<!-- #   theme_minimal() -->


<!-- ``` -->

<!-- ---------------------- -->
<!--  UMAP -->

<!-- ```{r} -->
<!-- library(embed) -->

<!-- umap_rec <- recipe(~., data = pca_data) %>% -->
<!--   update_role(studid, new_role = "id") %>% -->
<!--   step_normalize(all_predictors()) %>% -->
<!--   step_umap(all_predictors()) -->

<!-- umap_prep <- prep(umap_rec) -->

<!-- bake(umap_prep, new_data = NULL) %>% -->
<!--   ggplot(aes(UMAP1, UMAP2, label = studid)) + -->
<!--   geom_point(color = "midnightblue", alpha = 0.7, size = 2) + -->
<!--   geom_text(check_overlap = TRUE, hjust = "inward", family = "IBMPlexSans") + -->
<!--   labs(color = NULL) -->
<!-- ``` -->





