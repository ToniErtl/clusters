---
title: "demeaned_clustering"
author: "Antal Ertl"
date: '2023 03 01 '
output: html_document
---

```{r setup, include=FALSE}

library(tidyverse)
#library(tidymodels)
library(ggplot2)
library(ggthemes)

library(rgl) # 3 dimensional plots
library(factoextra)
library(crosstable) # crosstable function


# Clustering methods:
library(cluster)

# For random forest modeling and visualization:
library(rpart)
library(partykit)
library(party)


corrplot2 <- function(data,
                      method = "pearson",
                      sig.level = 0.05,
                      order = "original",
                      diag = FALSE,
                      type = "upper",
                      tl.srt = 90,
                      number.font = 1,
                      number.cex = 1,
                      mar = c(0, 0, 0, 0)) {
  library(corrplot)
  data_incomplete <- data
  data <- data[complete.cases(data), ]
  mat <- cor(data, method = method)
  cor.mtest <- function(mat, method) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat <- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
      for (j in (i + 1):n) {
        tmp <- cor.test(mat[, i], mat[, j], method = method)
        p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
      }
    }
    colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
    p.mat
  }
  p.mat <- cor.mtest(data, method = method)
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  corrplot(mat,
    method = "color", col = col(200), number.font = number.font,
    mar = mar, number.cex = number.cex,
    type = type, order = order,
    addCoef.col = "black", # add correlation coefficient
    tl.col = "black", tl.srt = tl.srt, # rotation of text labels
    # combine with significance level
    p.mat = p.mat, sig.level = sig.level, insig = "blank",
    # hide correlation coefficiens on the diagonal
    diag = diag
  )
}

```

```{r load data}
data <- read.csv(".//Data in brief//Horn-Kiss-Lenard2021.csv")
```

demeanelni osztályonként az összes score-t:

- classid-nként megnézni az átlagot és ahhoz képest mennyi standard eloszlásra van az adott ember adott scoreból

ezekre a deamenelt scoreokra futtatni az egészet

osztály átlag hisztogramok az egyes nem demeanelt változókra.

Április 20-21

---------------------------------------------


```{r}

pca_data <- data %>%  mutate(STournamentChoosed =replace_na(STournamentChoosed,0)) %>%
        mutate(STournamentChoosed_comp =STournamentChoosed* comp) %>%
                     dplyr::select(studid,
                                   classid,
                                   delta,
                                   #delta_now,
                                   beta,
                                   #pb,
                                   beta_0, # time inconsistency
                                   dictator, #altruism
                                   dictator_schoolmate, #altruism
                                   risk, # risk
                                   publicgood, # cooperativeness
                                   trust, # trust
                                   trust_return) %>%  #trust
  drop_na() 



# demean: redefine variable where we indicate for each individual how many standard deviations he or she is from the class average

pca_data_demeaned<- data %>%  mutate(STournamentChoosed =replace_na(STournamentChoosed,0)) %>%
                    mutate(STournamentChoosed_comp =STournamentChoosed* comp) %>%
                     dplyr::select(studid,
                                   classid,
                                   delta,
                                   #delta_now,
                                   beta,
                                   #pb,
                                   beta_0, # time inconsistency
                                   dictator, #altruism
                                   dictator_schoolmate, #altruism
                                   risk, # risk
                                   publicgood, # cooperativeness
                                   trust, # trust
                                   trust_return) %>%  #trust
  drop_na() %>% 
  group_by(classid) %>% 
  mutate(#mean values: 
         mean_delta= mean(delta),
         mean_beta = mean(beta),
         mean_beta_0 = mean(beta_0),
         mean_dictator = mean(dictator),
         mean_dictator_schoolmate = mean(dictator_schoolmate),
         mean_risk = mean(risk),
         mean_publicgood = mean(publicgood),
         mean_trust = mean(trust),
         mean_trust_return = mean(trust_return),
         #standard deviations:
         sd_delta = sd(delta),
         sd_beta = sd(beta),
         sd_beta_0 = sd(beta_0),
         sd_dictator = sd(dictator),
         sd_dictator_schoolmate = sd(dictator_schoolmate),
         sd_risk = sd(risk),
         sd_publicgood = sd(publicgood),
         sd_trust = sd(trust),
         sd_trust_return = sd(trust_return)) %>% 
  ungroup() %>% 
  # calculate how many standard deviations one observation is from the mean
  mutate(delta_diff = (delta - mean_delta ) / sd_delta,
         beta_diff = (beta - mean_beta ) / sd_beta,
         beta_0_diff = (beta_0 - mean_beta_0 ) / sd_beta_0,
         dictator_diff = (dictator - mean_dictator ) / sd_dictator,
         dictator_schoolmate_diff = (dictator_schoolmate - mean_dictator_schoolmate ) / sd_dictator_schoolmate,
         risk_diff = (risk - mean_risk ) / sd_risk,
         publicgood_diff = (publicgood - mean_publicgood ) / sd_publicgood,
         trust_diff = (trust - mean_trust ) / sd_trust,
         trust_return_diff = (trust_return - mean_trust_return ) / sd_trust_return,
         ) %>%
  select(studid,classid,delta_diff,beta_diff,beta_0_diff,dictator_diff,dictator_schoolmate_diff,
         risk_diff,publicgood_diff,trust_diff,trust_return_diff)
  # mutate(delta_diff = (delta / sd_delta) - mean_delta,
  #        beta_diff = (beta / sd_beta) - mean_beta ,
  #        beta_0_diff = (beta_0 / sd_beta_0) - mean_beta_0 ,
  #        dictator_diff = (dictator / sd_dictator) - mean_dictator ,
  #        dictator_schoolmate_diff = (dictator_schoolmate / sd_dictator_schoolmate) - mean_dictator_schoolmate ,
  #        risk_diff = (risk / sd_risk) - mean_risk,
  #        publicgood_diff = (publicgood / sd_publicgood) - mean_publicgood ,
  #        trust_diff = (trust / sd_trust) - mean_trust ,
  #        trust_return_diff = (trust_return / sd_trust_return) - mean_trust_return ,
  #        ) %>%
  # select(studid,classid,delta_diff,beta_diff,beta_0_diff,dictator_diff,dictator_schoolmate_diff,
  #        risk_diff,publicgood_diff,trust_diff,trust_return_diff)


```




### Defining the number of Principal Components to look at 


Using the demeaned data, the factor choice is no longer clear at factor = 4 but it is good enough




```{r, warning=FALSE,dpi=300, fig.width=10, fig.height=4}

pr.out <- pca_data_demeaned %>% select(-studid,-classid) %>% prcomp(., scale = TRUE)


scree_plot_data <- pca_data_demeaned %>%  select(-studid,-classid) %>% psych::principal( nfactors = 4, rotate= "varimax")

pve <- 100 * pr.out$sdev^2 / sum(pr.out$sdev ^2)
par(mfrow = c(1, 2))
plot(pve , type = "o", ylab = "PVE", main = "Scree-plot for Principal Component Analysis", frame = FALSE, xlab = "Principal Component", col = "blue")
```


Alternatively, look at the number of Principal Components to attaint using Parallel Analysis.

Parallel Analysis: specify how many components to retain using simulation

Here, we get the critical values for each component. If the eigenvalues from the PCA are greater than the value at 0.95 confint, we can retain given component.

We have two rules:
1) Kaiser's rule: Eigenvalue has to be >1 (satisfied up to 4 factors, with the 4th being barely above)
2) Eigenvalues being greater than the estimates gathered from Parallel Analysis (Horn, 1965)

```{r, warning=FALSE}


library(hornpa)
hornpa(k = 4, #test for number of factors
       size = nrow(pca_data_demeaned), # size of dataset
       reps = 500, # number of simulations
       seed = 1234) #set seed


scree_plot_data <- pca_data_demeaned %>%  select(-studid,-classid) %>% psych::principal( nfactors = 4, rotate= "varimax")
scree_plot_data



rm(scree_plot_data,pve)
```


Overall, no clear indication on the number of components; still, in order to make it comparable with the non-demeaned data, I calculate with 4 factors in the PCA.



### 3 Factor PCA



```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}

pca_varimax<- pca_data_demeaned %>%  select(-studid,-classid) %>% psych::principal( nfactors = 3, rotate= "varimax")



data.frame(head(pca_varimax$loadings, n=nrow(pca_varimax$loadings))) %>%
  mutate(variable = rownames(.)) %>%
  gather(component,loading,-variable) %>%
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component",
      subtitle ="With 3 factors",
      caption = "diff = [ y -avg(y)  / sd(y)] ")+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()
```



#### 4 Factor PCA 





```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}

pca_varimax<- pca_data_demeaned %>%  select(-studid,-classid) %>% psych::principal( nfactors = 4, rotate= "varimax")


pca_varimax$loadings

data.frame(head(pca_varimax$loadings, n=nrow(pca_varimax$loadings))) %>%
  mutate(variable = rownames(.)) %>%
  gather(component,loading,-variable) %>%
  ggplot(aes(loading,variable))+
  geom_col(fill = "midnightblue")+
  facet_wrap(~component,nrow=1)+
    labs(color = NULL,
       title = "Factor Loadings for each Component",
      subtitle ="With 4 factors",
      caption = "diff = [ y -avg(y)  / sd(y)] ")+
  ylab(NULL)+
  xlab(NULL)+
  theme_minimal()
```


Bottom line: demeaned megmaradtak ugyanazok az eredmények

--------------------


```{r}


pca_varimax<- pca_data_demeaned %>%  select(-studid,-classid) %>% psych::principal( nfactors = 4, rotate= "varimax")


# RC1.: interakciót igénylő társas preferenciák
# RC2: időpreferencia
# RC4: Interakciót nem igénylő társas preferenciák
# RC3: kockázati preferencia




pca_data_demeaned$pca_socpref_interact <- pca_varimax$scores[,1]
pca_data_demeaned$pca_timepref <- pca_varimax$scores[,2]
pca_data_demeaned$pca_socpref_nointeract <- pca_varimax$scores[,4]
pca_data_demeaned$pca_riskpref <- pca_varimax$scores[,3]





# add variables from the original data

additional_variables <- data %>%
select(studid,
        schoolid,
         academic,
         comp,
         FinalProfitRounded,
         math,
         read,
         female,
         male,
         age,
         gpa_i,
         grade_math,
         grade_hun,
         grade_lit)



data_analysis <- left_join(pca_data_demeaned,additional_variables, by ="studid")



data_analysis_clean <- data_analysis %>%
  # select(-delta, # I am removing all data that pca components include
  #        -beta,
  #        -beta_0,
  #        -dictator,
  #        -dictator_schoolmate,
  #        -risk,
  #        -publicgood,
  #        -trust,
  #        -trust_return)%>%
  drop_na() %>%
  mutate(good_stud = case_when(gpa_i>=4.75~1,
                               TRUE~0))



data_analysis_clean_clusteringdata <- data_analysis_clean %>% select(pca_socpref_interact,
                                                                     pca_timepref,
                                                                     pca_socpref_nointeract,
                                                                     pca_riskpref)

```



```{r}

plot3d(
  x=pca_data_demeaned$pca_socpref_interact, y=pca_data_demeaned$pca_timepref, z=pca_data_demeaned$pca_socpref_nointeract,
  #col = data$color,
  #type = 's',
  radius = .1,
  xlab="Soc. Pref. Interact.", ylab="Time Pref.", zlab="Soc. Pref. No-Interact.")

```











----------------------
## Random Forest

Random forest math változóra; PCA változók nélkül



```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}

set.seed(425643)

rf_rpart <- rpart::rpart(math~delta_diff+beta_diff+dictator_diff+dictator_schoolmate_diff+risk_diff+publicgood_diff+
                           trust_diff+trust_return_diff+
                           comp, data=data_analysis_clean)


# to plot this, we need to make this compatible with the "party" package


rf_rpart2 <- partykit::as.party(rf_rpart)
plot(rf_rpart2)
```

Összehasonlítás a nyers változókkal:

```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}

set.seed(4286)


data_nomiss <- data %>% 
          dplyr::select(math,delta,beta,dictator,dictator_schoolmate,risk,publicgood,
                           trust,trust_return, comp) %>% 
  drop_na()

rf_rpart <- rpart::rpart(math~delta+beta+dictator+dictator_schoolmate+risk+publicgood+
                           trust+trust_return+
                           comp, data=data_nomiss)


# to plot this, we need to make this compatible with the "party" package


rf_rpart2 <- partykit::as.party(rf_rpart)
plot(rf_rpart2)


rm(data_nomiss)
```



Random Forest PCA-kkal:

```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}

set.seed(425643231)

rf_rpart <- rpart::rpart(math~pca_socpref_interact+pca_timepref+
                              pca_socpref_nointeract+pca_riskpref, data=data_analysis_clean)


# to plot this, we need to make this compatible with the "party" package


rf_rpart2 <- partykit::as.party(rf_rpart)
plot(rf_rpart2)
```






# Clustering

Hierarchical clustering:


```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}

hc.complete <- hclust(dist(data_analysis_clean_clusteringdata), method = "complete")
dendagram <- as.dendrogram(hc.complete)

LAB = rep("", nobs(dendagram))
dendagram = dendextend::set(dendagram, "labels", LAB)

plot(dendextend::color_branches(dendagram, k = 6), main="Clusters created at height = 6.5", sub ="5 clusters with one outlier", leaflab = "none", horiz = F)
abline(h = 6.5, col = 'red')





# save the clusters:




```


K-means clustering:

As a first step, I check the optimal number of clusters using the elbow-plot; the results show that 5 is optimal, which is in line with the hierarchical clustering method.

```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}
# elbow method:
set.seed(123)

# function to compute total within-cluster sum of square
wss <- function(k) {
  kmeans(data_analysis_clean_clusteringdata, k, nstart = 100 )$tot.withinss
}

# Compute and plot wss for k = 1 to k = 15
k.values <- 1:50

# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE,
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
```

Now knowing that the number of factors is the same, I run the K-means clustering algorithm for 5 clusters:


```{r warning=FALSE,dpi=300, fig.width=10, fig.height=4}
set.seed(123469)
k5 <- kmeans(data_analysis_clean_clusteringdata, centers = 5, nstart = 10000)


fviz_cluster(k5, geom = "point",  data = data_analysis_clean_clusteringdata) + ggtitle("Clusters with 5 centers and 10,000 simulations")+
  theme_minimal()


# get classes:


# hierarchical clustering:
cut_complete <- cutree(hc.complete, h=6.5)

data_analysis_clean_clusteringdata$hierarchical_cluster <- cut_complete


#k-means:
data_analysis_clean_clusteringdata$kmeans_cluster <- k5$cluster
```



#### Cross-table of various observations using the two clustering algorithms:

```{r}
table(data_analysis_clean_clusteringdata$hierarchical_cluster,data_analysis_clean_clusteringdata$kmeans_cluster)
```










